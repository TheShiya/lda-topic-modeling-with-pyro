{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implemented by Liushiya Chen (lc3501@columbia.edu) for COMS 6998\n",
    "reference: http://www.cs.columbia.edu/~blei/fogm/2015F/notes/mixed-membership.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"import pyro\\nimport pyro.distributions as dist\\nimport torch\\n\\n\\ndef mixed_membership_model(alpha, nu, num_docs, num_words, vocab):\\n\\n    # Each topic is a categorical distribution over words. E.g. topics[i] = {word1: 0.2, word2: 0.8}\\n    topics = [\\n        pyro.sample(\\\"topic_{}\\\".format(i), dist.Dirichlet(nu)) for i in range(len(alpha))\\n    ]\\n\\n    # Every document is a categorical distribution over topics. E.g. documents[i] = {science: 0.2, business: 0.8}\\n    documents = [\\n        pyro.sample(\\\"doc_{}\\\".format(i), dist.Dirichlet(alpha)) for i in range(num_docs)\\n    ]\\n\\n    # A corpus is a set of documents\\n    corpus = []\\n\\n    for i in range(num_docs):\\n        document = []\\n        for j in range(num_words):\\n            topic_id = pyro.sample(\\n                \\\"assigned_topic_{}_{}\\\".format(i, j), dist.Categorical(documents[i])\\n            )\\n            word_id = pyro.sample(\\n                \\\"word_id_{}_{}\\\".format(i, j), dist.Categorical(topics[topic_id])\\n            )\\n            document.append(vocab[word_id])\\n        corpus.append(document)\\n    return corpus\";\n",
       "                var nbb_formatted_code = \"import pyro\\nimport pyro.distributions as dist\\nimport torch\\n\\n\\ndef mixed_membership_model(alpha, nu, num_docs, num_words, vocab):\\n\\n    # Each topic is a categorical distribution over words. E.g. topics[i] = {word1: 0.2, word2: 0.8}\\n    topics = [\\n        pyro.sample(\\\"topic_{}\\\".format(i), dist.Dirichlet(nu)) for i in range(len(alpha))\\n    ]\\n\\n    # Every document is a categorical distribution over topics. E.g. documents[i] = {science: 0.2, business: 0.8}\\n    documents = [\\n        pyro.sample(\\\"doc_{}\\\".format(i), dist.Dirichlet(alpha)) for i in range(num_docs)\\n    ]\\n\\n    # A corpus is a set of documents\\n    corpus = []\\n\\n    for i in range(num_docs):\\n        document = []\\n        for j in range(num_words):\\n            topic_id = pyro.sample(\\n                \\\"assigned_topic_{}_{}\\\".format(i, j), dist.Categorical(documents[i])\\n            )\\n            word_id = pyro.sample(\\n                \\\"word_id_{}_{}\\\".format(i, j), dist.Categorical(topics[topic_id])\\n            )\\n            document.append(vocab[word_id])\\n        corpus.append(document)\\n    return corpus\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "\n",
    "\n",
    "def mixed_membership_model(alpha, nu, num_docs, num_words, vocab):\n",
    "\n",
    "    # Each topic is a categorical distribution over words. E.g. topics[i] = {word1: 0.2, word2: 0.8}\n",
    "    topics = [\n",
    "        pyro.sample(\"topic_{}\".format(i), dist.Dirichlet(nu)) for i in range(len(alpha))\n",
    "    ]\n",
    "\n",
    "    # Every document is a categorical distribution over topics. E.g. documents[i] = {science: 0.2, business: 0.8}\n",
    "    documents = [\n",
    "        pyro.sample(\"doc_{}\".format(i), dist.Dirichlet(alpha)) for i in range(num_docs)\n",
    "    ]\n",
    "\n",
    "    # A corpus is a set of documents\n",
    "    corpus = []\n",
    "\n",
    "    for i in range(num_docs):\n",
    "        document = []\n",
    "        for j in range(num_words):\n",
    "            topic_id = pyro.sample(\n",
    "                \"assigned_topic_{}_{}\".format(i, j), dist.Categorical(documents[i])\n",
    "            )\n",
    "            word_id = pyro.sample(\n",
    "                \"word_id_{}_{}\".format(i, j), dist.Categorical(topics[topic_id])\n",
    "            )\n",
    "            document.append(vocab[word_id])\n",
    "        corpus.append(document)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core government chimney settle adjust drag enlarge retain bottom idea designer budget knot settle snow leak comprehensive factor adjust drag.\n",
      "knot bottom sensitive chimney defendant adjust drag bottom relaxation comprehensive bottom budget drag knot budget core bottom relaxation exception retreat.\n",
      "relaxation core knot grace factor leak defendant colon concrete drag concrete bottom guilt grace issue idea guilt designer idea idea.\n",
      "drag harmful comprehensive budget stick exception harmful defendant bottom leak sensitive adjust complex retreat adjust adjust snow snow stick knot.\n",
      "guilt idea budget drag retain guilt guilt adjust issue comprehensive government defendant settle snow drag stick bottom leak drag defendant.\n",
      "concrete budget concrete factor comprehensive retreat factor exception idea budget harmful relaxation settle bottom settle factor knot exception guilt exception.\n",
      "concrete harmful chimney snow leak factor sensitive concrete bottom core relaxation settle government guilt colon concrete drag budget exception breeze.\n",
      "bottom drag adjust harmful leak guilt factor idea settle adjust defendant retreat knot adjust retain comprehensive designer breeze bottom leak.\n",
      "concrete sensitive settle factor defendant settle stick harmful core comprehensive concrete exception factor chimney defendant comprehensive retain drag budget adjust.\n",
      "guilt comprehensive drag stick designer harmful sensitive government exception core budget drag budget leak knot drag guilt stick concrete retreat.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 74;\n",
       "                var nbb_unformatted_code = \"VOCAB = [\\n    \\\"budget\\\",\\n    \\\"leak\\\",\\n    \\\"designer\\\",\\n    \\\"raid\\\",\\n    \\\"colon\\\",\\n    \\\"grace\\\",\\n    \\\"defendant\\\",\\n    \\\"comprehensive\\\",\\n    \\\"retreat\\\",\\n    \\\"factor\\\",\\n    \\\"adjust\\\",\\n    \\\"drag\\\",\\n    \\\"complex\\\",\\n    \\\"retain\\\",\\n    \\\"relaxation\\\",\\n    \\\"government\\\",\\n    \\\"breeze\\\",\\n    \\\"idea\\\",\\n    \\\"concrete\\\",\\n    \\\"chimney\\\",\\n    \\\"bottom\\\",\\n    \\\"snow\\\",\\n    \\\"knot\\\",\\n    \\\"stick\\\",\\n    \\\"guilt\\\",\\n    \\\"exception\\\",\\n    \\\"sensitive\\\",\\n    \\\"settle\\\",\\n    \\\"enlarge\\\",\\n    \\\"issue\\\",\\n    \\\"harmful\\\",\\n    \\\"core\\\",\\n]\\n\\nn_topics = 3\\nvocab_size = len(VOCAB)\\nalpha = torch.ones(n_topics)\\nnu = torch.ones(vocab_size)\\nnum_docs = 10\\nnum_words = 20\\n\\nsampled_corpus = mixed_membership_model(alpha, nu, num_docs, num_words, VOCAB)\\nfor doc in sampled_corpus:\\n    print(\\\" \\\".join(doc) + \\\".\\\")\";\n",
       "                var nbb_formatted_code = \"VOCAB = [\\n    \\\"budget\\\",\\n    \\\"leak\\\",\\n    \\\"designer\\\",\\n    \\\"raid\\\",\\n    \\\"colon\\\",\\n    \\\"grace\\\",\\n    \\\"defendant\\\",\\n    \\\"comprehensive\\\",\\n    \\\"retreat\\\",\\n    \\\"factor\\\",\\n    \\\"adjust\\\",\\n    \\\"drag\\\",\\n    \\\"complex\\\",\\n    \\\"retain\\\",\\n    \\\"relaxation\\\",\\n    \\\"government\\\",\\n    \\\"breeze\\\",\\n    \\\"idea\\\",\\n    \\\"concrete\\\",\\n    \\\"chimney\\\",\\n    \\\"bottom\\\",\\n    \\\"snow\\\",\\n    \\\"knot\\\",\\n    \\\"stick\\\",\\n    \\\"guilt\\\",\\n    \\\"exception\\\",\\n    \\\"sensitive\\\",\\n    \\\"settle\\\",\\n    \\\"enlarge\\\",\\n    \\\"issue\\\",\\n    \\\"harmful\\\",\\n    \\\"core\\\",\\n]\\n\\nn_topics = 3\\nvocab_size = len(VOCAB)\\nalpha = torch.ones(n_topics)\\nnu = torch.ones(vocab_size)\\nnum_docs = 10\\nnum_words = 20\\n\\nsampled_corpus = mixed_membership_model(alpha, nu, num_docs, num_words, VOCAB)\\nfor doc in sampled_corpus:\\n    print(\\\" \\\".join(doc) + \\\".\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VOCAB = [\n",
    "    \"budget\",\n",
    "    \"leak\",\n",
    "    \"designer\",\n",
    "    \"raid\",\n",
    "    \"colon\",\n",
    "    \"grace\",\n",
    "    \"defendant\",\n",
    "    \"comprehensive\",\n",
    "    \"retreat\",\n",
    "    \"factor\",\n",
    "    \"adjust\",\n",
    "    \"drag\",\n",
    "    \"complex\",\n",
    "    \"retain\",\n",
    "    \"relaxation\",\n",
    "    \"government\",\n",
    "    \"breeze\",\n",
    "    \"idea\",\n",
    "    \"concrete\",\n",
    "    \"chimney\",\n",
    "    \"bottom\",\n",
    "    \"snow\",\n",
    "    \"knot\",\n",
    "    \"stick\",\n",
    "    \"guilt\",\n",
    "    \"exception\",\n",
    "    \"sensitive\",\n",
    "    \"settle\",\n",
    "    \"enlarge\",\n",
    "    \"issue\",\n",
    "    \"harmful\",\n",
    "    \"core\",\n",
    "]\n",
    "\n",
    "n_topics = 3\n",
    "vocab_size = len(VOCAB)\n",
    "alpha = torch.ones(n_topics)\n",
    "nu = torch.ones(vocab_size)\n",
    "num_docs = 10\n",
    "num_words = 20\n",
    "\n",
    "sampled_corpus = mixed_membership_model(alpha, nu, num_docs, num_words, VOCAB)\n",
    "for doc in sampled_corpus:\n",
    "    print(\" \".join(doc) + \".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
