{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 359;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 374;\n",
       "                var nbb_unformatted_code = \"import pyro\\nimport numpy as np\\nimport pandas as pd\\nimport torch\\nimport pyro.distributions as dist\\nimport math, time\\nimport torch.distributions.constraints as constraints\\nimport matplotlib.pyplot as plt\\nfrom pyro.infer import SVI, Trace_ELBO\\nfrom pyro.optim import Adam\\nfrom IPython.display import display, clear_output\";\n",
       "                var nbb_formatted_code = \"import pyro\\nimport numpy as np\\nimport pandas as pd\\nimport torch\\nimport pyro.distributions as dist\\nimport math, time\\nimport torch.distributions.constraints as constraints\\nimport matplotlib.pyplot as plt\\nfrom pyro.infer import SVI, Trace_ELBO\\nfrom pyro.optim import Adam\\nfrom IPython.display import display, clear_output\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "import math, time\n",
    "import torch.distributions.constraints as constraints\n",
    "import matplotlib.pyplot as plt\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 2])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 378;\n",
       "                var nbb_unformatted_code = \"ndocs = 2\\nntopics = 3\\nnwords = 13\\nvocab_size = 6\\n\\ndef lda(data):\\n    alpha_prior = torch.ones(ntopics)\\n    nu_prior = torch.ones(vocab_size)\\n    with pyro.plate(\\\"topic_loop\\\", ntopics):\\n        topics = pyro.sample(\\\"topics\\\", dist.Dirichlet(nu_prior.repeat(ntopics, 1)))  # Sample topics\\n    with pyro.plate(\\\"doc_loop\\\", ndocs) as ind:\\n        data = data[:, ind]\\n        theta = pyro.sample(\\\"theta\\\", dist.Dirichlet(alpha_prior))#.repeat(ndocs, 1)))\\n        with pyro.plate(\\\"word_loop\\\", nwords):\\n            z = pyro.sample(\\\"z\\\", dist.Categorical(theta))\\n            w = pyro.sample(\\\"w\\\", dist.Categorical(topics[z]), obs=data)\\n\\ndef guide(data):\\n    lambda_q = pyro.param(\\\"lambda_q\\\", torch.ones(ntopics, vocab_size), constraint=constraints.positive)\\n    gamma_q = pyro.param(\\\"gamma_q\\\", torch.ones(ndocs, ntopics), constraint=constraints.positive)\\n    phi_q = pyro.param(\\\"phi_q\\\", torch.ones(nwords, ndocs, ntopics), constraint=constraints.positive)\\n\\n    with pyro.plate(\\\"topic_loop\\\", ntopics):\\n        topics = pyro.sample(\\\"topics\\\", dist.Dirichlet(lambda_q))  # Sample topics\\n    with pyro.plate(\\\"doc_loop\\\", ndocs):\\n        theta = pyro.sample(\\\"theta\\\", dist.Dirichlet(gamma_q))#.repeat(ndocs, 1)))\\n        with pyro.plate(\\\"word_loop\\\", nwords):\\n            z = pyro.sample(\\\"z\\\", dist.Categorical(phi_q))\\n\\n\\n\\ndef generate():\\n    alpha_prior = torch.ones(ntopics)\\n    nu_prior = torch.ones(vocab_size)\\n    data = torch.zeros([nwords, ndocs])\\n    topics = pyro.sample(\\\"topics\\\", dist.Dirichlet(nu_prior.repeat(ntopics, 1))) \\n    for d in pyro.plate(\\\"doc_loop\\\", ndocs):\\n        theta = pyro.sample(f\\\"theta_{d}\\\", dist.Dirichlet(alpha_prior))\\n        for w in pyro.iarange(\\\"word_loop\\\", nwords):\\n            z = pyro.sample(f\\\"z_{d}_{w}\\\", dist.Categorical(theta))\\n            word = pyro.sample(f\\\"w_{d}_{w}\\\", dist.Categorical(topics[z.item()]))\\n            data[w, d] = word\\n    return data, topics\\n\\nvocab = [\\\"banana\\\", \\\"carrot\\\", \\\"cake\\\", \\\"milk\\\", \\\"diapers\\\", \\\"beer\\\"]\\ndata, topics = generate()\\ndata.shape\";\n",
       "                var nbb_formatted_code = \"ndocs = 2\\nntopics = 3\\nnwords = 13\\nvocab_size = 6\\n\\n\\ndef lda(data):\\n    alpha_prior = torch.ones(ntopics)\\n    nu_prior = torch.ones(vocab_size)\\n    with pyro.plate(\\\"topic_loop\\\", ntopics):\\n        topics = pyro.sample(\\n            \\\"topics\\\", dist.Dirichlet(nu_prior.repeat(ntopics, 1))\\n        )  # Sample topics\\n    with pyro.plate(\\\"doc_loop\\\", ndocs) as ind:\\n        data = data[:, ind]\\n        theta = pyro.sample(\\\"theta\\\", dist.Dirichlet(alpha_prior))  # .repeat(ndocs, 1)))\\n        with pyro.plate(\\\"word_loop\\\", nwords):\\n            z = pyro.sample(\\\"z\\\", dist.Categorical(theta))\\n            w = pyro.sample(\\\"w\\\", dist.Categorical(topics[z]), obs=data)\\n\\n\\ndef guide(data):\\n    lambda_q = pyro.param(\\n        \\\"lambda_q\\\", torch.ones(ntopics, vocab_size), constraint=constraints.positive\\n    )\\n    gamma_q = pyro.param(\\n        \\\"gamma_q\\\", torch.ones(ndocs, ntopics), constraint=constraints.positive\\n    )\\n    phi_q = pyro.param(\\n        \\\"phi_q\\\", torch.ones(nwords, ndocs, ntopics), constraint=constraints.positive\\n    )\\n\\n    with pyro.plate(\\\"topic_loop\\\", ntopics):\\n        topics = pyro.sample(\\\"topics\\\", dist.Dirichlet(lambda_q))  # Sample topics\\n    with pyro.plate(\\\"doc_loop\\\", ndocs):\\n        theta = pyro.sample(\\\"theta\\\", dist.Dirichlet(gamma_q))  # .repeat(ndocs, 1)))\\n        with pyro.plate(\\\"word_loop\\\", nwords):\\n            z = pyro.sample(\\\"z\\\", dist.Categorical(phi_q))\\n\\n\\ndef generate():\\n    alpha_prior = torch.ones(ntopics)\\n    nu_prior = torch.ones(vocab_size)\\n    data = torch.zeros([nwords, ndocs])\\n    topics = pyro.sample(\\\"topics\\\", dist.Dirichlet(nu_prior.repeat(ntopics, 1)))\\n    for d in pyro.plate(\\\"doc_loop\\\", ndocs):\\n        theta = pyro.sample(f\\\"theta_{d}\\\", dist.Dirichlet(alpha_prior))\\n        for w in pyro.iarange(\\\"word_loop\\\", nwords):\\n            z = pyro.sample(f\\\"z_{d}_{w}\\\", dist.Categorical(theta))\\n            word = pyro.sample(f\\\"w_{d}_{w}\\\", dist.Categorical(topics[z.item()]))\\n            data[w, d] = word\\n    return data, topics\\n\\n\\nvocab = [\\\"banana\\\", \\\"carrot\\\", \\\"cake\\\", \\\"milk\\\", \\\"diapers\\\", \\\"beer\\\"]\\ndata, topics = generate()\\ndata.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndocs = 2\n",
    "ntopics = 3\n",
    "nwords = 13\n",
    "vocab_size = 6\n",
    "\n",
    "\n",
    "def lda(data):\n",
    "    alpha_prior = torch.ones(ntopics)\n",
    "    nu_prior = torch.ones(vocab_size)\n",
    "    with pyro.plate(\"topic_loop\", ntopics):\n",
    "        topics = pyro.sample(\n",
    "            \"topics\", dist.Dirichlet(nu_prior.repeat(ntopics, 1))\n",
    "        )  # Sample topics\n",
    "    with pyro.plate(\"doc_loop\", ndocs) as ind:\n",
    "        data = data[:, ind]\n",
    "        theta = pyro.sample(\"theta\", dist.Dirichlet(alpha_prior))  # .repeat(ndocs, 1)))\n",
    "        with pyro.plate(\"word_loop\", nwords):\n",
    "            z = pyro.sample(\"z\", dist.Categorical(theta))\n",
    "            w = pyro.sample(\"w\", dist.Categorical(topics[z]), obs=data)\n",
    "\n",
    "\n",
    "def guide(data):\n",
    "    lambda_q = pyro.param(\n",
    "        \"lambda_q\", torch.ones(ntopics, vocab_size), constraint=constraints.positive\n",
    "    )\n",
    "    gamma_q = pyro.param(\n",
    "        \"gamma_q\", torch.ones(ndocs, ntopics), constraint=constraints.positive\n",
    "    )\n",
    "    phi_q = pyro.param(\n",
    "        \"phi_q\", torch.ones(nwords, ndocs, ntopics), constraint=constraints.positive\n",
    "    )\n",
    "\n",
    "    with pyro.plate(\"topic_loop\", ntopics):\n",
    "        topics = pyro.sample(\"topics\", dist.Dirichlet(lambda_q))  # Sample topics\n",
    "    with pyro.plate(\"doc_loop\", ndocs):\n",
    "        theta = pyro.sample(\"theta\", dist.Dirichlet(gamma_q))  # .repeat(ndocs, 1)))\n",
    "        with pyro.plate(\"word_loop\", nwords):\n",
    "            z = pyro.sample(\"z\", dist.Categorical(phi_q))\n",
    "\n",
    "\n",
    "def generate():\n",
    "    alpha_prior = torch.ones(ntopics)\n",
    "    nu_prior = torch.ones(vocab_size)\n",
    "    data = torch.zeros([nwords, ndocs])\n",
    "    topics = pyro.sample(\"topics\", dist.Dirichlet(nu_prior.repeat(ntopics, 1)))\n",
    "    for d in pyro.plate(\"doc_loop\", ndocs):\n",
    "        theta = pyro.sample(f\"theta_{d}\", dist.Dirichlet(alpha_prior))\n",
    "        for w in pyro.iarange(\"word_loop\", nwords):\n",
    "            z = pyro.sample(f\"z_{d}_{w}\", dist.Categorical(theta))\n",
    "            word = pyro.sample(f\"w_{d}_{w}\", dist.Categorical(topics[z.item()]))\n",
    "            data[w, d] = word\n",
    "    return data, topics\n",
    "\n",
    "\n",
    "vocab = [\"banana\", \"carrot\", \"cake\", \"milk\", \"diapers\", \"beer\"]\n",
    "data, topics = generate()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................."
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "# set up the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(lda, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "loss = []\n",
    "n_steps = 50000\n",
    "for step in range(n_steps):\n",
    "    loss.append(svi.step(data))\n",
    "    if step % (n_steps//100) == 0:\n",
    "        print(\".\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.Series(loss), alpha=0.3, label=\"Actual\")\n",
    "plt.plot(pd.Series(loss).rolling(100).mean(), alpha=1, label=\"100 rolling mean\")\n",
    "plt.legend()\n",
    "plt.title(\"ELBO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
